---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

Maybe add in an auto grabber to the web with json
Add some SQLite db stuff

```{r, message = F, warning = F}
library(ggplot2)
library(dplyr)
library(data.table)
library(RSQLite)
library(tmap)
library(tmaptools)
library(sf)
# library(Hmisc)
library(tidyr)
# library(plyr)
# library(reshape2)
library(knitr)
library(kableExtra)
library(xml2)
```


```{r, cache = T}
popEst <- read.csv('./data/1710013501_databaseLoadingData.csv', 
                          na.strings = c('', '<NA>'))
```

### Check Data Integrity

```{r}
for(i in colnames(popEst)){
        i_unique <- uniqueN(popEst[,i])
        cmd <- sprintf('Unique values for %s: %d', i, i_unique)
        print(eval(cmd))
}
#OR
#sapply(popEst, uniqueN)
as.data.frame(colMeans(is.na(popEst))*100) %>% 
        kbl() %>% 
        kable_styling(bootstrap_options = c('striped', 
                                      'hover', 
                                      'condensed', 
                                      'responsive'), 
                      full_width = F)
```

A couple quick commands to see Some variables have a large amount of NA values, and some don't provide any useful information (only contains one unique value).
Here we remove the columns that are all the same or all NA:

```{r}
badCols <- c()
for (i in colnames(popEst)) {
        i_unique <- uniqueN(popEst[,i])
        if (i_unique == 1) {
                badCols <- append(badCols, TRUE)
        } else {
                badCols <- append(badCols, FALSE)
        }
}
popEst <- popEst[,!badCols]
```

### Transformation

```{r}
colnames(popEst) <- c('YEAR', 'GEO', 'DGUID', 'VECTOR', 'COORDINATE', 'POPULATION')
popEst$GEO <- gsub('Ã©', 'é', popEst$GEO)
popEst$GEO <- gsub('Ã¨', 'è', popEst$GEO)
popEst$GEO <- gsub('ÃŽ', 'Î', popEst$GEO)
popEst$CITY <- gsub('( \\(CMA\\)).*|( \\(CA\\)).*', '', popEst$GEO)
popEst$PROVINCE <- gsub('.*( \\(CMA\\)), |.*( \\(CA\\)), ', '', popEst$GEO)
popEst <- popEst[!grepl("census| part, ", popEst$GEO),]
popEst <- spread(popEst, YEAR, POPULATION)
popEst[,c(1:6)] <- lapply(popEst[,c(1:6)], factor)
```

Changed the column names
Created variables for city and province
Created 

```{r}
str(popEst)
```

Now to get the lat/lon data
Campbellton, Restigouche County, NB
Hawkesbury, Prescott and Russell Counties, Eastern Ontario, Ontario, Canada
```{r}
popEst$lat <- NA
popEst$lon <- NA
for(n in 1:nrow(popEst)) {
        tryCatch({
                address <- paste0(popEst$CITY[n], ', ', popEst$PROVINCE[n])
                geo_address <- NA
                geo_address <- geocode_OSM(address, as.data.frame = T)
                popEst$lat[n] <- geo_address[2]
                popEst$lon[n] <- geo_address[3]
                }, finally = next)
}
```

The required search query for Campbellton and Hawkesbury is oddly specific, so I had to manually search for them.

```{r}
sum(is.na(popEst$lat))
campbelltonGeo <- geocode_OSM('Campbellton, Restigouche County, NB', as.data.frame = T)
hawkesburyGeo <- geocode_OSM('Hawkesbury, Prescott and Russell Counties, Eastern Ontario, Ontario, Canada', as.data.frame = T)
popEst$lat[grepl('Campbellton', popEst$CITY)] <- campbelltonGeo[2]
popEst$lon[grepl('Campbellton', popEst$CITY)] <- campbelltonGeo[3]
popEst$lat[grepl('Hawkesbury', popEst$CITY)] <- hawkesburyGeo[2]
popEst$lon[grepl('Hawkesbury', popEst$CITY)] <- hawkesburyGeo[3]
sum(is.na(popEst$lat))
```

```{r}
for (city in popEst$CITY) {
        print(paste(city, '|', grep(city, shp$CDNAME)))
}
```

```{r}
popEstsf <- popEst %>% st_as_sf(coords = c('lon', 'lat'))
```

https://norrisresearch.com/kml/census/2016/census_2016_csd.centre.kmz

```{r}
kml <- st_read('./data/census_2016_csd_centre/census_2016_csd_centre.kml', stringsAsFactors = FALSE)
```
```{r}
layers <- st_layers('./data/census_2016_csd_centre/census_2016_csd_centre.kml')
```

```{r}
kml_xml <- read_xml('./data/census_2016_csd_centre/census_2016_csd_centre.kml')
```

```{r, cache = T}
kml <- list()
for (n in 1:length(layers[[1]])) {
        kml[[n]] <- st_read('./data/census_2016_csd_centre/census_2016_csd_centre.kml', stringsAsFactors = F, layer = layers[[1]][n])
}
```

```{r, cache = T}
CDUID <- c()
for (n in 1:length(popEst$CITY)) {
        tryCatch({
                city <- popEst$CITY[n]
                kml_loc <- grep(city, kml)
                CDUID[n] <- kml[[kml_loc[1]]][[1]][grep(city, kml[[kml_loc[1]]][[1]])]
        }, finally = next)
}
```
```{r}
gsub('.*\\[|...\\]', '', CDUID)
```

Get and format shp file

```{r, cache = TRUE}
shp <- st_read("./data/lcma000b16a_e/lcma000b16a_e.shp", stringsAsFactors = FALSE)
```

```{r}
map <- tm_shape(shp) + tm_polygons()
```

```{r}
map
```



```{r}
subdiv <- read.csv('./data/17100142-eng/17100142.csv', na.strings = '')
```
```{r}
shpdiv <- st_read("./data/lcsd000b16a_e/lcsd000b16a_e.shp", 
                  stringsAsFactors = FALSE)
```




